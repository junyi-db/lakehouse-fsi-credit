{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "177c6158-ce8b-47c0-bf83-0b87fa019790",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Simplify Ingestion and Transformation with Delta Live Tables\n",
    "\n",
    "In this notebook, we'll work as a Data Engineer to build our Credit Decisioning database. <br>\n",
    "We'll consume and clean our raw data sources to prepare the tables required for our BI & ML workload.\n",
    "\n",
    "We have four data sources sending new files in our blob storage and we want to incrementally load this data into our Data warehousing tables:\n",
    "\n",
    "- **Internal banking** data *(KYC, accounts, collections, applications, relationship)* come from the bank's internal relational databases and is ingested *once a day* through a CDC pipeline,\n",
    "- **Credit Bureau** data (usually in XML or CSV format and *accessed monthly* through API) comes from government agencies (such as a central banks) and contains a lot of valuable information for every customer. We also use this data to re-calculate whether a user has defaulted in the past 60 days,\n",
    "- **Partner** data - used to augment the internal banking data and ingested *once a week*. In this case we use telco data in order to further evaluate the character and creditworthiness of banking customers,\n",
    "- **Fund transfer** are the banking transactions (such as credit card transactions) and are *available real-time* through Kafka streams.\n",
    "\n",
    "\n",
    "## Delta Live Table: A simple way to build and manage data pipelines for fresh, high quality data!\n",
    "\n",
    "\n",
    "Databricks simplifies this task with Delta Live Table (DLT) by making Data Engineering accessible to all.\n",
    "\n",
    "DLT allows Data Analysts to create advanced pipeline with plain SQL.\n",
    "\n",
    "<div>\n",
    "  <div style=\"width: 45%; float: left; margin-bottom: 10px; padding-right: 45px\">\n",
    "    <p>\n",
    "      <img style=\"width: 50px; float: left; margin: 0px 5px 30px 0px;\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/logo-accelerate.png\"/> \n",
    "      <strong>Accelerate ETL development</strong> <br/>\n",
    "      Enable analysts and data engineers to innovate rapidly with simple pipeline development and maintenance \n",
    "    </p>\n",
    "    <p>\n",
    "      <img style=\"width: 50px; float: left; margin: 0px 5px 30px 0px;\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/logo-complexity.png\"/> \n",
    "      <strong>Remove operational complexity</strong> <br/>\n",
    "      By automating complex administrative tasks and gaining broader visibility into pipeline operations\n",
    "    </p>\n",
    "  </div>\n",
    "  <div style=\"width: 48%; float: left\">\n",
    "    <p>\n",
    "      <img style=\"width: 50px; float: left; margin: 0px 5px 30px 0px;\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/logo-trust.png\"/> \n",
    "      <strong>Trust your data</strong> <br/>\n",
    "      With built-in quality controls and quality monitoring to ensure accurate and useful BI, Data Science, and ML \n",
    "    </p>\n",
    "    <p>\n",
    "      <img style=\"width: 50px; float: left; margin: 0px 5px 30px 0px;\" src=\"https://raw.githubusercontent.com/QuentinAmbard/databricks-demo/main/retail/resources/images/lakehouse-retail/logo-stream.png\"/> \n",
    "      <strong>Simplify batch and streaming</strong> <br/>\n",
    "      With self-optimization and auto-scaling data pipelines for batch or streaming processing \n",
    "    </p>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "<br style=\"clear:both\">\n",
    "\n",
    "<img src=\"https://pages.databricks.com/rs/094-YMS-629/images/delta-lake-logo.png\" style=\"float: right;\" width=\"200px\">\n",
    "\n",
    "## Delta Lake\n",
    "\n",
    "All the tables we'll create in the Lakehouse will be stored as Delta Lake tables. Delta Lake is an open storage framework for reliability and performance.<br>\n",
    "It provides many functionalities (ACID Transaction, DELETE/UPDATE/MERGE, Clone zero copy, Change data Capture...)<br>\n",
    "For more details on Delta Lake, run dbdemos.install('delta-lake')\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=1444828305810485&notebook=%2F01-Data-Ingestion%2F01-DLT-Internal-Banking-Data-SQL&demo_name=lakehouse-fsi-credit&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-credit%2F01-Data-Ingestion%2F01-DLT-Internal-Banking-Data-SQL&version=1&user_hash=7804490f0d3be4559d29a7b52959f461489c4ee5e35d4afc7b55f311360ac589\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2a1ff85e-a389-4caa-8df3-be04036f39a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Building a Delta Live Table pipeline to analyze consumer credit\n",
    "\n",
    "In this example, we'll implement an end-to-end DLT pipeline consuming the aforementioned information. We'll use the medaillon architecture but we could build star schema, data vault, or any other modelisation.\n",
    "\n",
    "We'll incrementally load new data with the autoloader, enrich this information and then load a model from MLFlow to perform our credit decisioning prediction.\n",
    "\n",
    "This information will then be used to build our DBSQL dashboard to create credit scores, decisioning, and risk.\n",
    "\n",
    "Let's implement the following flow: \n",
    " \n",
    "<div><img width=\"1000px\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi_credit_decisioning_dlt_0.png\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea5e2627-0361-4078-b443-c6148d819021",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Your DLT Pipeline has been installed and started for you! Open the <a dbdemos-pipeline-id=\"dlt-fsi-credit-decisioning\" href=\"#joblist/pipelines\" target=\"_blank\">Delta Live Table pipeline</a> to see it in action.<br/>\n",
    "*(Note: The pipeline will automatically start once the initialization job is completed, this might take a few minutes... Check installation logs for more details)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "ed038384-ead0-4a07-be6b-fdbf106ae526",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 1/ Loading our data using Databricks Autoloader (cloud_files)\n",
    "\n",
    "<img width=\"650px\" style=\"float:right\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi_credit_decisioning_dlt_1.png\"/>\n",
    "  \n",
    "Autoloader allow us to efficiently ingest millions of files from a cloud storage, and support efficient schema inference and evolution at scale.\n",
    "\n",
    "For more details on autoloader, run `dbdemos.install('auto-loader')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a2b2156-7d23-494a-a23a-4fba88b33dab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1. Credit Bureau\n",
    "\n",
    "Credit bureau data refers to information about an individual's credit history, financial behavior, and creditworthiness that is collected and maintained by credit bureaus. Credit bureaus are companies that collect and compile information about consumers' credit activities, such as credit card usage, loan payments, and other financial transactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b622ddc6-bac6-4b82-afcb-f65bd6958f52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE credit_bureau_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/credit_bureau', 'json',\n",
    "                 map('header', 'true', \n",
    "                     'inferSchema', 'true', \n",
    "                     'cloudFiles.inferColumnTypes', 'true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f95db4b-41e2-4fb6-ade3-84652efc2850",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 1. Customer table\n",
    "\n",
    "The customer table comes from the internal KYC processes and contains customer-related data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2dd9a27d-06f7-4a18-abb0-fc8aea9bf77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE customer_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/internalbanking/customer', 'csv',\n",
    "                 map('header', 'true', \n",
    "                     'inferSchema', 'true', \n",
    "                     'cloudFiles.inferColumnTypes', 'true',\n",
    "                     'cloudFiles.schemaHints', 'passport_expiry date, visa_expiry date, join_date date, dob date'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4db149c0-90b7-4d0a-a5d4-024e0e089c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 2. Relationship table\n",
    "\n",
    "The relationship table represents the relationship between the bank and the customer. It also comes from the raw databases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34bbf8a3-5457-4f3d-89bb-5c6ebe8c6929",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE relationship_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/internalbanking/relationship', 'csv',\n",
    "                 map('header', 'true', \n",
    "                     'inferSchema', 'true', \n",
    "                     'cloudFiles.inferColumnTypes', 'true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe09ecfd-dc4d-4ca5-8b93-bf43efa39982",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 3. Account table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca67a239-8c6c-481a-a5de-2390848c4e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE account_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/internalbanking/account', 'csv',\n",
    "                 map('header', 'true', \n",
    "                     'inferSchema', 'true', \n",
    "                     'cloudFiles.inferColumnTypes', 'true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "86636ce1-4c8a-4aa0-935e-dee6e4f56800",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 4. Fund Transfer Table\n",
    "\n",
    "Fund transfer is a real-time data stream that contains payment transactions performed by the client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fab31eff-0b18-451d-8653-b42a6dd5e2da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE fund_trans_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/fund_trans', 'json',\n",
    "                map('inferSchema', 'true', \n",
    "                    'cloudFiles.inferColumnTypes', 'true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d06261-fb8d-416d-8933-da5b79158e7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 5. Telco\n",
    "\n",
    "This is where we augment the internal banking data through external and alternative data sources - in this case, telecom partner data, containing payment features for the common customers (between the bank and the telco provider)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e17307a-a61b-4210-a051-9878219ab924",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH STREAMING TABLE telco_bronze AS\n",
    "  SELECT * FROM\n",
    "    cloud_files('/Volumes/jy_demo_catalog/jy_fsi_credit_schema/credit_raw_data/telco', 'json',\n",
    "                 map('inferSchema', 'true',\n",
    "                     'cloudFiles.inferColumnTypes', 'true'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "1577a6fb-bca7-4eb8-96d5-cc3b818d27bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 2/ Enforce quality and materialize our tables for Data Analysts\n",
    "\n",
    "<img width=\"650px\" style=\"float:right\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi_credit_decisioning_dlt_2.png\"/>\n",
    "\n",
    "The next layer often call silver is consuming **incremental** data from the bronze one, and cleaning up some information.\n",
    "\n",
    "We're also adding an [expectation](https://docs.databricks.com/workflows/delta-live-tables/delta-live-tables-expectations.html) on different field to enforce and track our Data Quality. This will ensure that our dashboard are relevant and easily spot potential errors due to data anomaly.\n",
    "\n",
    "For more advanced DLT capabilities run `dbdemos.install('dlt-loans')` or `dbdemos.install('dlt-cdc')` for CDC/SCDT2 example.\n",
    "\n",
    "These tables are clean and ready to be used by the BI team!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1ea1b5cf-f785-41f3-a7bb-7ddea5acc347",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 1. Fund transfer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57f0dc2a-49fd-4756-93d9-5dc8ab930658",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW fund_trans_silver AS\n",
    "  SELECT\n",
    "    payer_account.cust_id payer_cust_id,\n",
    "    payee_account.cust_id payee_cust_id,\n",
    "    fund.*\n",
    "  FROM\n",
    "    live.fund_trans_bronze fund\n",
    "  LEFT OUTER JOIN live.account_bronze payer_account ON fund.payer_acc_id = payer_account.id\n",
    "  LEFT OUTER JOIN live.account_bronze payee_account ON fund.payee_acc_id = payee_account.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "10432fac-3726-4ea2-bbbd-b6f52778cf1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 2. Customer table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7c96c48-2f87-4eac-96bf-6fba9b04f431",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW customer_silver AS\n",
    "  SELECT\n",
    "    * EXCEPT (dob, customer._rescued_data, relationship._rescued_data, relationship.id, relationship.operation),\n",
    "    year(dob) AS birth_year\n",
    "  FROM\n",
    "    live.customer_bronze customer\n",
    "  LEFT OUTER JOIN live.relationship_bronze relationship ON customer.id = relationship.cust_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2b94a812-fbb5-49ab-bdd1-231b610c71d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 3. Account table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30a94a53-07fe-44c3-8dcc-9ac1eee6ce1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW account_silver AS\n",
    "  WITH cust_acc AS (\n",
    "      SELECT cust_id, count(1) num_accs, avg(balance) avg_balance \n",
    "        FROM live.account_bronze\n",
    "        GROUP BY cust_id\n",
    "    )\n",
    "  SELECT\n",
    "    acc_usd.cust_id,\n",
    "    num_accs,\n",
    "    avg_balance,\n",
    "    balance balance_usd,\n",
    "    available_balance available_balance_usd,\n",
    "    operation\n",
    "  FROM\n",
    "    cust_acc\n",
    "  LEFT OUTER JOIN live.account_bronze acc_usd ON cust_acc.cust_id = acc_usd.cust_id AND acc_usd.currency = 'USD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "9788dfb1-3823-4145-a2a6-45807d28686d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "### 3/ Aggregation layer for analytics & ML\n",
    "\n",
    "<img width=\"650px\" style=\"float:right\" src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi_credit_decisioning_dlt_3.png\"/>\n",
    "\n",
    "We curate all the tables in Delta Lake using Delta Live Tables so we can apply all the joins, masking, and data constraints in real-time. Data scientists can now use these datasets to built high-quality models, particularly to predict credit worthiness. Because we are masking sensitive data as part of Unity Catalog capabilities, we are able to confidently expose the data to many downstream users from data scientists to data analysts and business users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7c3ca7a-cd0b-4222-ba55-ea16740655b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 1. Credit bureau cleanup\n",
    "\n",
    "We begin by ingesting credit bureau data, sourced from a Delta Lake table here. Typically, this data would be curated via API ingestion and dumped into cloud object stores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6800e37-0e39-41db-b76c-00a84ca3b91c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW credit_bureau_gold\n",
    "  (CONSTRAINT CustomerID_not_null EXPECT (CUST_ID IS NOT NULL) ON VIOLATION DROP ROW)\n",
    "AS\n",
    "  SELECT * FROM live.credit_bureau_bronze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84ddfd02-ad08-439d-b31f-c39a1685954d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 1. Fund transfer table\n",
    "\n",
    "The fund transfer table represents peer-to-peer payments made between the customer and another person. This helps us to understand the frequency and monetary attributes for payments for each customer as a credit risk source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46f7ec45-42e9-4554-a996-90bfa6885d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW fund_trans_gold AS (\n",
    "  WITH \n",
    "    max_date AS (SELECT max(datetime) AS max_date FROM live.fund_trans_silver),\n",
    "    12m_payer AS (SELECT\n",
    "                      payer_cust_id,\n",
    "                      COUNT(DISTINCT payer_cust_id) dist_payer_cnt_12m,\n",
    "                      COUNT(1) sent_txn_cnt_12m,\n",
    "                      SUM(txn_amt) sent_txn_amt_12m,\n",
    "                      AVG(txn_amt) sent_amt_avg_12m\n",
    "                    FROM live.fund_trans_silver WHERE cast(datetime AS date) >= date_add(MONTH, -12, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                    GROUP BY payer_cust_id),\n",
    "      12m_payee AS (SELECT\n",
    "                        payee_cust_id,\n",
    "                        COUNT(DISTINCT payee_cust_id) dist_payee_cnt_12m,\n",
    "                        COUNT(1) rcvd_txn_cnt_12m,\n",
    "                        SUM(txn_amt) rcvd_txn_amt_12m,\n",
    "                        AVG(txn_amt) rcvd_amt_avg_12m\n",
    "                      FROM live.fund_trans_silver WHERE CAST(datetime AS date) >= date_add(MONTH, -12, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                      GROUP BY payee_cust_id),\n",
    "      6m_payer AS (SELECT\n",
    "                    payer_cust_id,\n",
    "                    COUNT(DISTINCT payer_cust_id) dist_payer_cnt_6m,\n",
    "                    COUNT(1) sent_txn_cnt_6m,\n",
    "                    SUM(txn_amt) sent_txn_amt_6m,\n",
    "                    AVG(txn_amt) sent_amt_avg_6m\n",
    "                  FROM live.fund_trans_silver WHERE CAST(datetime AS date) >= date_add(MONTH, -6, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                  GROUP BY payer_cust_id),\n",
    "      6m_payee AS (SELECT\n",
    "                    payee_cust_id,\n",
    "                    COUNT(DISTINCT payee_cust_id) dist_payee_cnt_6m,\n",
    "                    COUNT(1) rcvd_txn_cnt_6m,\n",
    "                    SUM(txn_amt) rcvd_txn_amt_6m,\n",
    "                    AVG(txn_amt) rcvd_amt_avg_6m\n",
    "                  FROM live.fund_trans_silver WHERE CAST(datetime AS date) >= date_add(MONTH, -6, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                  GROUP BY payee_cust_id),\n",
    "      3m_payer AS (SELECT\n",
    "                    payer_cust_id,\n",
    "                    COUNT(DISTINCT payer_cust_id) dist_payer_cnt_3m,\n",
    "                    COUNT(1) sent_txn_cnt_3m,\n",
    "                    SUM(txn_amt) sent_txn_amt_3m,\n",
    "                    AVG(txn_amt) sent_amt_avg_3m\n",
    "                  FROM live.fund_trans_silver WHERE CAST(datetime AS date) >= date_add(MONTH, -3, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                  GROUP BY payer_cust_id),\n",
    "      3m_payee AS (SELECT\n",
    "                    payee_cust_id,\n",
    "                    COUNT(DISTINCT payee_cust_id) dist_payee_cnt_3m,\n",
    "                    COUNT(1) rcvd_txn_cnt_3m,\n",
    "                    SUM(txn_amt) rcvd_txn_amt_3m,\n",
    "                    AVG(txn_amt) rcvd_amt_avg_3m\n",
    "                  FROM live.fund_trans_silver WHERE CAST(datetime AS date) >= date_add(MONTH, -3, (SELECT CAST(max_date AS date) FROM max_date))\n",
    "                  GROUP BY payee_cust_id)        \n",
    "  SELECT c.cust_id, \n",
    "    12m_payer.* EXCEPT (payer_cust_id),\n",
    "    12m_payee.* EXCEPT (payee_cust_id), \n",
    "    6m_payer.* EXCEPT (payer_cust_id), \n",
    "    6m_payee.* EXCEPT (payee_cust_id), \n",
    "    3m_payer.* EXCEPT (payer_cust_id), \n",
    "    3m_payee.* EXCEPT (payee_cust_id) \n",
    "  FROM live.customer_silver c \n",
    "    LEFT JOIN 12m_payer ON 12m_payer.payer_cust_id = c.cust_id\n",
    "    LEFT JOIN 12m_payee ON 12m_payee.payee_cust_id = c.cust_id\n",
    "    LEFT JOIN 6m_payer ON 6m_payer.payer_cust_id = c.cust_id\n",
    "    LEFT JOIN 6m_payee ON 6m_payee.payee_cust_id = c.cust_id\n",
    "    LEFT JOIN 3m_payer ON 3m_payer.payer_cust_id = c.cust_id\n",
    "    LEFT JOIN 3m_payee ON 3m_payee.payee_cust_id = c.cust_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "07d200bd-7a62-4b83-ac03-4f8b2ba6f308",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 3. Telco table\n",
    "\n",
    "The telco table represents all the payments data for a given prospect or customer to understand credit worthiness based on a non-bank credit source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca17b18f-81bb-4b73-ad39-7039ad984e5d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW telco_gold AS\n",
    "SELECT\n",
    "  customer.id cust_id,\n",
    "  telco.*\n",
    "FROM\n",
    "  live.telco_bronze telco\n",
    "  LEFT OUTER JOIN live.customer_bronze customer ON telco.user_phone = customer.mobile_phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "142a9c08-b2e6-40ad-bc0e-9a35c7ece01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 4. Customer table\n",
    "\n",
    "The customer data represents the system of record for PII and customer attributes that will be joined to other fact tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f1c6a9f-4ce2-4f95-beda-2ffbea5f6017",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REFRESH MATERIALIZED VIEW customer_gold AS\n",
    "SELECT\n",
    "  customer.*,\n",
    "  account.avg_balance,\n",
    "  account.num_accs,\n",
    "  account.balance_usd,\n",
    "  account.available_balance_usd\n",
    "FROM\n",
    "  live.customer_silver customer\n",
    "  LEFT OUTER JOIN live.account_silver account ON customer.cust_id = account.cust_id "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff132ed3-f390-45d8-a321-99df6be932e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#### 5. Adding a view removing firstname for our datas scientist users\n",
    "\n",
    "The best practice for masking data in Databricks Delta Lake tables is to use dynamic views and functions like is_member to encrypt or mask data based on the group. In this case, we want to mask PII data based on user group, and we are using built-in encryption functions `aes_encrypt` to do this. Moreover, the key itself is saved into a Databricks secret for security reasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "939834e9-30d9-4bcf-87c5-a76892303801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE LIVE VIEW customer_gold_secured AS\n",
    "SELECT\n",
    "  c.* EXCEPT (first_name),\n",
    "  CASE\n",
    "    WHEN is_member('data-science-users')\n",
    "    THEN base64(aes_encrypt(c.first_name, 'YOUR_SECRET_FROM_MANAGER')) -- save secret in Databricks manager and load it in SQL with secret('<YOUR_SCOPE> ', '<YOUR_SECRET_NAME>')\n",
    "    ELSE c.first_name\n",
    "  END AS first_name\n",
    "FROM\n",
    "  live.customer_gold AS c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7537230-0e04-45f9-a7a0-68cb39f0a450",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Next: secure and share data with Unity Catalog\n",
    "\n",
    "Now that we have ingested all these various sources of data, we can jump to the:\n",
    "\n",
    "* [Governance with Unity Catalog notebook]($../02-Data-Governance/02-Data-Governance-credit-decisioning) to see how to grant fine-grained access to every user and persona and explore the **data lineage graph**,\n",
    "* [Feature Engineering notebook]($../03-Data-Science-ML/03.1-Feature-Engineering-credit-decisioning) and start creating features for our machine learning models,\n",
    "* Go back to the [Introduction]($../00-Credit-Decisioning)."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "01-DLT-Internal-Banking-Data-SQL",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
