{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "091e68f3-4c95-4431-9152-555587d85cf8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# ML: predict credit owners with high default probability\n",
    "\n",
    "Once all data is loaded and secured (the **data unification** part), we can proceed to exploring, understanding, and using the data to create actionable insights - **data decisioning**.\n",
    "\n",
    "\n",
    "As outlined in the [introductory notebook]($../00-Credit-Decisioning), we will build machine learning (ML) models for driving three business outcomes:\n",
    "1. Identify currently underbanked customers with high credit worthiness so we can offer them credit instruments,\n",
    "2. Predict current credit owners with high probability of defaulting along with the loss-given default, and\n",
    "3. Offer instantaneous micro-loans (Buy Now, Pay Later) when a customer does not have the required credit limit or account balance to complete a transaction.\n",
    "\n",
    "Here is the flow we'll implement: \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi-credit-decisioning-ml-0.png\" width=\"1200px\">\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=lakehouse&org_id=1444828305810485&notebook=%2F03-Data-Science-ML%2F03.1-Feature-Engineering-credit-decisioning&demo_name=lakehouse-fsi-credit&event=VIEW&path=%2F_dbdemos%2Flakehouse%2Flakehouse-fsi-credit%2F03-Data-Science-ML%2F03.1-Feature-Engineering-credit-decisioning&version=1&user_hash=7804490f0d3be4559d29a7b52959f461489c4ee5e35d4afc7b55f311360ac589\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c859b57-6459-4600-84c1-0bee16cda129",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### A cluster has been created for this demo\n",
    "To run this demo, just select the cluster `dbdemos-lakehouse-fsi-credit-junyi_tiong` from the dropdown menu ([open cluster configuration](https://e2-demo-field-eng.cloud.databricks.com/#setting/clusters/0922-083237-e7fg83pu/configuration)). <br />\n",
    "*Note: If the cluster was deleted after 30 days, you can re-create it with `dbdemos.create_cluster('lakehouse-fsi-credit')` or re-install the demo: `dbdemos.install('lakehouse-fsi-credit')`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e453ab5e-0583-4954-aab3-389e4b2f3012",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## The need for Enhanced Collaboration\n",
    "\n",
    "Feature Engineering is an iterative process - we need to quickly generate new features, test the model, and go back to feature selection and more feature engineering - many many times. The Databricks Lakehouse enables data teams to collaborate extremely effectively through the following Databricks Notebook features:\n",
    "1. Sharing and collaborating in the same Notebook by any team member (with different access modes),\n",
    "2. Ability to use python, SQL, and R simultaneously in the same Notebook on the same data,\n",
    "3. Native integration with a Git repository (including AWS Code Commit, Azure DevOps, GitLabs, Github, and others), making the Notebooks tools for CI/CD,\n",
    "4. Variables explorer,\n",
    "5. Automatic Data Profiling (in the cell below), and\n",
    "6. GUI-based dashboards (in the cell below) that can also be added to any Databricks SQL Dashboard.\n",
    "\n",
    "These features enable teams within FSI organizations to become extremely fast and efficient in building the best ML model at reduced time, thereby making the most out of market opportunities such as the raising interest rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a560474b-dc13-4b24-ac20-51f110d21f13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.36.0 mlflow==2.19.0 databricks-feature-store==0.17.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0eea8283-50c0-4740-b3d4-a3f9e91b9115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%run ../_resources/00-setup $reset_all_data=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "edf7ad3a-ea56-41a2-a9e8-0d4c9d2b45e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Data exploration & Features creation\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/databricks-demos/dbdemos-resources/main/images/fsi/credit_decisioning/fsi-credit-decisioning-ml-1.png\" style=\"float: right\" width=\"800px\">\n",
    "\n",
    "<br/><br/>\n",
    "The first step as Data Scientist is to explore our data and understand it to create Features.\n",
    "\n",
    "<br/>\n",
    "\n",
    "This where we use our existing tables and transform the data to be ready for our ML models. These features will later be stored in Databricks Feature Store (see below) and used to train the aforementioned ML models.\n",
    "\n",
    "<br/>\n",
    "\n",
    "Let's start with some data exploration. Databricks comes with built-in Data Profiling to help you bootstrap that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13428d55-a579-4105-9c6c-58e4858b0d5f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Use SQL to explore your data"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * FROM customer_gold WHERE tenure_months BETWEEN 10 AND 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb46de0a-bb09-487b-a8ad-6c46c802e853",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Our any of your usual python libraries for analysis"
    }
   },
   "outputs": [],
   "source": [
    "data = spark.table(\"customer_gold\") \\\n",
    "              .where(\"tenure_months BETWEEN 10 AND 150\") \\\n",
    "              .groupBy(\"tenure_months\", \"education\").sum(\"income_monthly\") \\\n",
    "              .orderBy('education').toPandas()\n",
    "\n",
    "px.bar(data, x=\"tenure_months\", y=\"sum(income_monthly)\", color=\"education\", title=\"Wide-Form Input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d80e55b-c311-4b81-bbce-d3e246b970f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Building our Features for Credit Default risks\n",
    "\n",
    "To build our model predicting credit default risks, we'll need a buch of features. To improve our governance and centralize our data for multiple ML project, we can save our ML features using a Feature Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4858f956-d2aa-4d95-8989-c27dc7b77a1e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read the customer table"
    }
   },
   "outputs": [],
   "source": [
    "customer_gold_features = (spark.table(\"customer_gold\")\n",
    "                               .withColumn('age', int(date.today().year) - col('birth_year'))\n",
    "                               .select('cust_id', 'education', 'marital_status', 'months_current_address', 'months_employment', 'is_resident',\n",
    "                                       'tenure_months', 'product_cnt', 'tot_rel_bal', 'revenue_tot', 'revenue_12m', 'income_annual', 'tot_assets', \n",
    "                                       'overdraft_balance_amount', 'overdraft_number', 'total_deposits_number', 'total_deposits_amount', 'total_equity_amount', \n",
    "                                       'total_UT', 'customer_revenue', 'age', 'avg_balance', 'num_accs', 'balance_usd', 'available_balance_usd')).dropDuplicates(['cust_id'])\n",
    "display(customer_gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d54161da-5b70-4d35-b3e2-fec7920f30a4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Read the telco table"
    }
   },
   "outputs": [],
   "source": [
    "telco_gold_features = (spark.table(\"telco_gold\")\n",
    "                            .select('cust_id', 'is_pre_paid', 'number_payment_delays_last12mo', 'pct_increase_annual_number_of_delays_last_3_year', 'phone_bill_amt', \\\n",
    "                                    'avg_phone_bill_amt_lst12mo')).dropDuplicates(['cust_id'])\n",
    "display(telco_gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dae012e0-301f-4c56-a7da-00bd5d3a8f4a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Adding some additional features on transactional trends"
    }
   },
   "outputs": [],
   "source": [
    "fund_trans_gold_features = spark.table(\"fund_trans_gold\").dropDuplicates(['cust_id'])\n",
    "\n",
    "for c in ['12m', '6m', '3m']:\n",
    "  fund_trans_gold_features = fund_trans_gold_features.withColumn('tot_txn_cnt_'+c, col('sent_txn_cnt_'+c)+col('rcvd_txn_cnt_'+c))\\\n",
    "                                                     .withColumn('tot_txn_amt_'+c, col('sent_txn_amt_'+c)+col('rcvd_txn_amt_'+c))\n",
    "\n",
    "fund_trans_gold_features = fund_trans_gold_features.withColumn('ratio_txn_amt_3m_12m', F.when(col('tot_txn_amt_12m')==0, 0).otherwise(col('tot_txn_amt_3m')/col('tot_txn_amt_12m')))\\\n",
    "                                                   .withColumn('ratio_txn_amt_6m_12m', F.when(col('tot_txn_amt_12m')==0, 0).otherwise(col('tot_txn_amt_6m')/col('tot_txn_amt_12m')))\\\n",
    "                                                   .na.fill(0)\n",
    "display(fund_trans_gold_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "009a4dda-a0f0-4cc1-bbd3-dd4b9ba55009",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Consolidating all the features"
    }
   },
   "outputs": [],
   "source": [
    "feature_df = customer_gold_features.join(telco_gold_features.alias('telco'), \"cust_id\", how=\"left\")\n",
    "feature_df = feature_df.join(fund_trans_gold_features, \"cust_id\", how=\"left\")\n",
    "display(feature_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "isMarkdownSandbox": true,
     "nuid": "57715dcd-3e03-4115-89e0-956aa8a4d5b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# Databricks Feature Store\n",
    "\n",
    "<img src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/product_demos/mlops-end2end-flow-feature-store.png\" style=\"float:right\" width=\"650\" />\n",
    "\n",
    "Once our features are ready, we'll save them in Databricks Feature Store. \n",
    "\n",
    "Under the hood, feature store are backed by a Delta Lake table. This will allow discoverability and reusability of our feature across our organization, increasing team efficiency.\n",
    "\n",
    "\n",
    "Databricks Feature Store brings advanced capabilities to accelerate and simplify your ML journey, such as point in time support and online-store, fetching your features within ms for real time Serving. \n",
    "\n",
    "### Why use Databricks Feature Store?\n",
    "\n",
    "Databricks Feature Store is fully integrated with other components of Databricks.\n",
    "\n",
    "* **Discoverability**. The Feature Store UI, accessible from the Databricks workspace, lets you browse and search for existing features.\n",
    "\n",
    "* **Lineage**. When you create a feature table with Feature Store, the data sources used to create the feature table are saved and accessible. For each feature in a feature table, you can also access the models, notebooks, jobs, and endpoints that use the feature.\n",
    "\n",
    "* **Batch and Online feature lookup for real time serving**. When you use features from Feature Store to train a model, the model is packaged with feature metadata. When you use the model for batch scoring or online inference, it automatically retrieves features from Feature Store. The caller does not need to know about them or include logic to look up or join features to score new data. This makes model deployment and updates much easier.\n",
    "\n",
    "* **Point-in-time lookups**. Feature Store supports time series and event-based use cases that require point-in-time correctness.\n",
    "\n",
    "\n",
    "For more details about Databricks Feature Store, run `dbdemos.install('feature-store')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6757270f-b878-4bb5-b08a-aa3cbcbd2c7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import feature_store\n",
    "fs = feature_store.FeatureStoreClient()\n",
    "\n",
    "# Drop the fs table if it was already existing to cleanup the demo state\n",
    "drop_fs_table(f\"{catalog}.{db}.credit_decisioning_features\")\n",
    "  \n",
    "fs.create_table(\n",
    "    name=f\"{catalog}.{db}.credit_decisioning_features\",\n",
    "    primary_keys=[\"cust_id\"],\n",
    "    df=feature_df,\n",
    "    description=\"Features for Credit Decisioning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22c6c8c6-fd76-4f92-a393-0dc66966957f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Next steps\n",
    "\n",
    "After creating our features and storing them in the Databricks Feature Store, we can now proceed to the [03.2-AutoML-credit-decisioning]($./03.2-AutoML-credit-decisioning) and build out credit decisioning model."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4640557381822675,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "03.1-Feature-Engineering-credit-decisioning",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
